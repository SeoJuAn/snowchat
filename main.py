# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main.py (2025-05-06 ì™„ì „ ìˆ˜ì •ë³¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# import os
# import re
# import warnings
# import json

# import streamlit as st
# from langchain_core.messages import HumanMessage
# from agent import MessagesState, create_agent
# from utils.snowchat_ui import StreamlitUICallbackHandler, message_func
# from utils.snowddl import Snowddl

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# warnings.filterwarnings("ignore")
# snow_ddl = Snowddl()

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¬¸ì„œ Â· SQL íŒŒì¼ ì½ê¸° ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def read_all_files(folder_path: str, file_ext: str) -> dict:
#     contents = {}
#     if os.path.exists(folder_path):
#         for filename in os.listdir(folder_path):
#             if filename.endswith(file_ext):
#                 with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
#                     contents[filename] = f.read()
#     return contents

# docs_content = read_all_files("docs", ".md")
# sql_content  = read_all_files("sql",  ".sql")

# def create_context_string() -> str:
#     parts = ["DOCUMENTATION FILES:"]
#     for fname, txt in docs_content.items():
#         parts.append(f"\n### {fname} ###\n{txt}\n")
#     parts.append("\nSQL FILES:")
#     for fname, txt in sql_content.items():
#         parts.append(f"\n### {fname} ###\n{txt}\n")
#     return "\n".join(parts)

# context_string = create_context_string()

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ€ì´í‹€ / ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# gradient_text_html = """
# <style>
# @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@700;900&display=swap');
# .snowchat-title {
#   font-family: 'Poppins', sans-serif;
#   font-weight: 900;
#   font-size: 4em;
#   background: linear-gradient(90deg,#ff6a00,#ee0979);
#   -webkit-background-clip:text;
#   -webkit-text-fill-color:transparent;
#   text-shadow:2px 2px 5px rgba(0,0,0,.3);
#   margin:0;padding:20px 0;text-align:center;
# }
# </style>
# <div class="snowchat-title">snowChat</div>
# """
# st.markdown(gradient_text_html, unsafe_allow_html=True)
# st.caption("Talk your way through data")

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# model_options = {
#     "o3-mini": "o3-mini",
#     "Qwen 2.5": "Qwen 2.5",
#     "Gemini 2.0 Flash": "Gemini 2.0 Flash",
#     "Grok 2": "Grok 2",
# }
# model = st.radio(
#     "Choose your AI Model:",
#     options=list(model_options.keys()),
#     format_func=lambda x: model_options[x],
#     index=0,
#     horizontal=True,
# )
# st.session_state["model"] = model

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SessionState ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# if "messages" not in st.session_state:
#     st.session_state["messages"] = []
# if "history" not in st.session_state:
#     st.session_state["history"] = []
# if "assistant_response_processed" not in st.session_state:
#     st.session_state["assistant_response_processed"] = True
# for flag in ("toast_shown", "rate-limit"):
#     if flag not in st.session_state:
#         st.session_state[flag] = False

# # ìµœì´ˆ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¸íŒ…
# INITIAL_MESSAGE = [
#     {"role": "user", "content": "Hi!"},
#     {
#         "role": "assistant",
#         "content": (
#             "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Chatty McQueryFaceì…ë‹ˆë‹¤. "
#             "SQLì„ ì‚¬ìš©í•˜ì—¬ Snowflake ë°ì´í„°ë² ì´ìŠ¤ë¥¼ íƒìƒ‰í•˜ëŠ” ë° ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”. "
#             "ë°ì´í„° ì‹œê°í™”ë„ í•  ìˆ˜ ìˆìœ¼ë‹ˆ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! â„ï¸ğŸ”"
#         ),
#     },
# ]
# if not st.session_state["messages"]:
#     st.session_state["messages"] = INITIAL_MESSAGE

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# with open("ui/sidebar.md", "r") as f:
#     st.sidebar.markdown(f.read())
# with open("ui/styles.md", "r") as f:
#     st.write(f.read(), unsafe_allow_html=True)

# if st.sidebar.button("Reset Chat"):
#     for k in list(st.session_state.keys()):
#         del st.session_state[k]
#     st.session_state["messages"] = INITIAL_MESSAGE
#     st.session_state["history"]  = []

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ìš©ì ì…ë ¥ & ë©”ì‹œì§€ ë Œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# if prompt := st.chat_input():
#     if len(prompt) > 500:
#         st.error("Input is too long! Please limit your message to 500 characters.")
#     else:
#         st.session_state["messages"].append({"role": "user", "content": prompt})
#         st.session_state["assistant_response_processed"] = False

# # ë©”ì‹œì§€Â·ì°¨íŠ¸ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
# for msg in st.session_state["messages"]:
#     if msg["role"] == "visualization":
#         st.components.v1.html(msg["content"], height=500, scrolling=False)
#     else:
#         message_func(
#             msg["content"],
#             is_user=(msg["role"] == "user"),
#             is_df=(msg["role"] == "data"),
#             model=model,
#         )

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# callback_handler = StreamlitUICallbackHandler(model)
# react_graph = create_agent(callback_handler, model, context_string)

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def append_message(content: str, role: str = "assistant"):
#     if content.strip():
#         st.session_state["messages"].append({"role": role, "content": content})

# def display_visualization(html: str):
#     """ì°¨íŠ¸ë¥¼ visualization ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ê³  ì¦‰ì‹œ ë Œë”"""
#     st.session_state["messages"].append({"role": "visualization", "content": html})
#     st.components.v1.html(html, height=500, scrolling=False)

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM / Tool ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# if (
#     st.session_state["messages"][-1]["role"] == "user"
#     and not st.session_state["assistant_response_processed"]
# ):
#     user_input = st.session_state["messages"][-1]["content"]
#     callback_handler.start_loading_message()

#     state  = MessagesState(messages=[HumanMessage(content=user_input)])
#     result = react_graph.invoke(
#         state,
#         config={"configurable": {"thread_id": "42"}},
#         debug=True,
#     )

#     # â”€â”€â”€â”€â”€ visualization íƒœê·¸ ì¶”ì¶œ â”€â”€â”€â”€â”€
#     viz_pattern = r"<visualization>(.*?)</visualization>"
#     viz_html = None

#     # 1) ToolMessage ë“¤ ë¨¼ì € ìŠ¤ìº”
#     for m in result["messages"]:
#         try:
#             if isinstance(m.content, str):
#                 found = re.search(viz_pattern, m.content, re.DOTALL)
#                 if found:
#                     viz_html = found.group(1)
#                     break
#         except AttributeError:
#             pass

#     # 2) assistant ìµœì¢… ë©”ì‹œì§€
#     assistant_msg = callback_handler.final_message
#     if viz_html is None:
#         found = re.search(viz_pattern, assistant_msg, re.DOTALL)
#         if found:
#             viz_html = found.group(1)
#             assistant_msg = re.sub(viz_pattern, "", assistant_msg, flags=re.DOTALL)
#     else:
#         assistant_msg = re.sub(viz_pattern, "", assistant_msg, flags=re.DOTALL)

#     # â”€â”€â”€â”€â”€ ê²°ê³¼ í‘œì‹œ â”€â”€â”€â”€â”€
#     append_message(assistant_msg)
#     if viz_html:
#         display_visualization(viz_html)

#     st.session_state["assistant_response_processed"] = True
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main.py (2025-05-06 ì™„ì „ ìˆ˜ì •ë³¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import re
import warnings
import json

import streamlit as st
from langchain_core.messages import HumanMessage
from agent import MessagesState, create_agent
from utils.snowchat_ui import StreamlitUICallbackHandler, message_func
from utils.snowddl import Snowddl

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore")
snow_ddl = Snowddl()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¬¸ì„œ Â· SQL íŒŒì¼ ì½ê¸° ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_all_files(folder_path: str, file_ext: str) -> dict:
    contents = {}
    if os.path.exists(folder_path):
        for filename in os.listdir(folder_path):
            if filename.endswith(file_ext):
                with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
                    contents[filename] = f.read()
    return contents

docs_content = read_all_files("docs", ".md")
sql_content  = read_all_files("sql",  ".sql")

def create_context_string() -> str:
    parts = ["DOCUMENTATION FILES:"]
    for fname, txt in docs_content.items():
        parts.append(f"\n### {fname} ###\n{txt}\n")
    parts.append("\nSQL FILES:")
    for fname, txt in sql_content.items():
        parts.append(f"\n### {fname} ###\n{txt}\n")
    return "\n".join(parts)

context_string = create_context_string()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ€ì´í‹€ / ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
gradient_text_html = """
<style>
@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@700;900&display=swap');
.snowchat-title {
  font-family: 'Poppins', sans-serif;
  font-weight: 900;
  font-size: 4em;
  background: linear-gradient(90deg,#ff6a00,#ee0979);
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
  text-shadow:2px 2px 5px rgba(0,0,0,.3);
  margin:0;padding:20px 0;text-align:center;
}
</style>
<div class="snowchat-title">snowChat</div>
"""
st.markdown(gradient_text_html, unsafe_allow_html=True)
st.caption("Talk your way through data")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_options = {
    "o3-mini": "o3-mini",
    "Qwen 2.5": "Qwen 2.5",
    "Gemini 2.0 Flash": "Gemini 2.0 Flash",
    "Grok 2": "Grok 2",
}
model = st.radio(
    "Choose your AI Model:",
    options=list(model_options.keys()),
    format_func=lambda x: model_options[x],
    index=0,
    horizontal=True,
)
st.session_state["model"] = model

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SessionState ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "history" not in st.session_state:
    st.session_state["history"] = []
if "assistant_response_processed" not in st.session_state:
    st.session_state["assistant_response_processed"] = True
for flag in ("toast_shown", "rate-limit"):
    if flag not in st.session_state:
        st.session_state[flag] = False

# ìµœì´ˆ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¸íŒ…
INITIAL_MESSAGE = [
    {"role": "user", "content": "Hi!"},
    {
        "role": "assistant",
        "content": (
            "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Chatty McQueryFaceì…ë‹ˆë‹¤. "
            "SQLì„ ì‚¬ìš©í•˜ì—¬ Snowflake ë°ì´í„°ë² ì´ìŠ¤ë¥¼ íƒìƒ‰í•˜ëŠ” ë° ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”. "
            "ë°ì´í„° ì‹œê°í™”ë„ í•  ìˆ˜ ìˆìœ¼ë‹ˆ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! â„ï¸ğŸ”"
        ),
    },
]
if not st.session_state["messages"]:
    st.session_state["messages"] = INITIAL_MESSAGE

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open("ui/sidebar.md", "r") as f:
    st.sidebar.markdown(f.read())
with open("ui/styles.md", "r") as f:
    st.write(f.read(), unsafe_allow_html=True)

if st.sidebar.button("Reset Chat"):
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.session_state["messages"] = INITIAL_MESSAGE
    st.session_state["history"]  = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ìš©ì ì…ë ¥ & ë©”ì‹œì§€ ë Œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if prompt := st.chat_input():
    if len(prompt) > 500:
        st.error("Input is too long! Please limit your message to 500 characters.")
    else:
        st.session_state["messages"].append({"role": "user", "content": prompt})
        st.session_state["assistant_response_processed"] = False

# ë©”ì‹œì§€Â·ì°¨íŠ¸ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
for msg in st.session_state["messages"]:
    if msg["role"] == "visualization":
        st.components.v1.html(msg["content"], height=500, scrolling=False)
    else:
        message_func(
            msg["content"],
            is_user=(msg["role"] == "user"),
            is_df=(msg["role"] == "data"),
            model=model,
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
callback_handler = StreamlitUICallbackHandler(model)
react_graph = create_agent(callback_handler, model, context_string)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def append_message(content: str, role: str = "assistant"):
    if content.strip():
        st.session_state["messages"].append({"role": role, "content": content})

def display_visualization(html: str):
    """ì°¨íŠ¸ë¥¼ visualization ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ê³  ì¦‰ì‹œ ë Œë”"""
    st.session_state["messages"].append({"role": "visualization", "content": html})
    st.components.v1.html(html, height=500, scrolling=False)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM / Tool ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if (
    st.session_state["messages"][-1]["role"] == "user"
    and not st.session_state["assistant_response_processed"]
):
    user_input = st.session_state["messages"][-1]["content"]
    callback_handler.start_loading_message()

    state  = MessagesState(messages=[HumanMessage(content=user_input)])
    result = react_graph.invoke(
        state,
        config={"configurable": {"thread_id": "42"}},
        debug=True,
    )

    viz_pattern = r"<visualization>(.*?)</visualization>"
    viz_html = None

    # â”€â”€â”€â”€â”€ 1) assistant ìµœì¢… ë©”ì‹œì§€ì—ì„œ ë¨¼ì € ì°¾ê¸° â”€â”€â”€â”€â”€
    assistant_msg = callback_handler.final_message
    match = re.search(viz_pattern, assistant_msg, re.DOTALL)
    if match:
        viz_html = match.group(1)
        assistant_msg = re.sub(viz_pattern, "", assistant_msg, flags=re.DOTALL)

    # â”€â”€â”€â”€â”€ 2) ì—†ìœ¼ë©´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ 'ì—­ìˆœ'ìœ¼ë¡œ ê²€ìƒ‰ â˜… â”€â”€â”€â”€â”€
    if viz_html is None:
        for m in reversed(result["messages"]):       # â˜… ìµœì‹ ë¶€í„° í™•ì¸
            try:
                if isinstance(m.content, str):
                    match = re.search(viz_pattern, m.content, re.DOTALL)
                    if match:
                        viz_html = match.group(1)
                        break                        # â˜… ìµœì‹  ì°¨íŠ¸ í•˜ë‚˜ë§Œ
            except AttributeError:
                pass

    # â”€â”€â”€â”€â”€ ê²°ê³¼ í‘œì‹œ â”€â”€â”€â”€â”€
    append_message(assistant_msg)
    if viz_html:
        display_visualization(viz_html)

    st.session_state["assistant_response_processed"] = True
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
